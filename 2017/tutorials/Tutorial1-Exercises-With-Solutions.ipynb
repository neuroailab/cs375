{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-2, 2, 101)[np.random.RandomState(0).permutation(101)]\n",
    "y = x ** 3 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Insert x and y into the database \"tasks\", collection \"polyfunction\" on host \"localhost\", port \"24444\", read it out again in sorted order print \"x\" and plot \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7ff68c81c950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = 24444\n",
    "host = 'localhost'\n",
    "connection = pm.MongoClient(port = port, host = host)\n",
    "\n",
    "entries = []\n",
    "for i in range(101):\n",
    "    entries.append({'x': x[i], 'y': y[i]})\n",
    "connection['tasks']['polyfunction'].insert_many(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entries = connection['tasks']['polyfunction'].find({'x': {'$exists' : True}}, projection=['x', 'y']).sort([('x',pm.ASCENDING)])\n",
    "x = [entry['x'] for entry in entries]\n",
    "print(x)\n",
    "entries = connection['tasks']['polyfunction'].find({'x': {'$exists' : True}}, projection=['x', 'y']).sort([('x',pm.ASCENDING)])\n",
    "y = [entry['y'] for entry in entries]\n",
    "plt.plot(x,y)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Run the script below which trains a MLP for the 10-way MNIST classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import division\n",
    "from tfutils import base, data, optimizer, utils\n",
    "\n",
    "# delete exp1\n",
    "connection['mnist']['simple.files'].delete_many({'exp_id' : 'exp1'})\n",
    "\n",
    "def mnist_model(inputs, train=True, **kwargs):\n",
    "    # trainable variables randomly initialized\n",
    "    with tf.variable_scope(\"mnist\"):\n",
    "        W1 = tf.get_variable('W1', [784,128], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b1 = tf.get_variable('b1', [128], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        W2 = tf.get_variable('W2', [128,32], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b2 = tf.get_variable('b2', [32], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        W3 = tf.get_variable('W3', [32,10], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b3 = tf.get_variable('b3', [10], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        \n",
    "        # hidden layers\n",
    "        h1 = tf.nn.sigmoid(tf.matmul(inputs['images'], W1) + b1, name='hidden1')\n",
    "        h2 = tf.nn.sigmoid(tf.matmul(h1, W2) + b2, name='hidden2')\n",
    "        # output\n",
    "        output = tf.matmul(h2, W3) + b3\n",
    "\n",
    "    return output, {}\n",
    "\n",
    "params = {}\n",
    "\n",
    "params['load_params'] = {\n",
    "    'do_restore': False}\n",
    "\n",
    "params['save_params'] = {\n",
    "    'host': 'localhost',\n",
    "    'port': 24444,\n",
    "    'dbname': 'mnist',\n",
    "    'collname': 'simple',\n",
    "    'exp_id': 'exp1',\n",
    "    'save_valid_freq': 200,\n",
    "    'save_filters_freq': 100,\n",
    "    'cache_filters_freq': 100}\n",
    "\n",
    "params['train_params'] = {\n",
    "    'data_params': {'func': data.MNIST,\n",
    "                    'batch_size': 256,\n",
    "                    'group': 'train',\n",
    "                    'n_threads': 1},\n",
    "    'queue_params': {'queue_type': 'random',\n",
    "                     'batch_size': 256},\n",
    "    'num_steps': 100}\n",
    "\n",
    "params['model_params'] = {\n",
    "    'func': mnist_model} \n",
    "\n",
    "params['learning_rate_params'] = {\n",
    "    'learning_rate': 0.5,\n",
    "    'decay_steps': 500,\n",
    "    'decay_rate': 0.95,\n",
    "    'staircase': True}\n",
    "\n",
    "params['optimizer_params'] = {\n",
    "    'func': optimizer.ClipOptimizer,\n",
    "    'optimizer_class': tf.train.MomentumOptimizer,\n",
    "    'momentum': 0.9,\n",
    "    'clip': True,\n",
    "}\n",
    "\n",
    "params['loss_params'] = {\n",
    "    'targets': ['labels'],\n",
    "    'loss_per_case_func': tf.nn.sparse_softmax_cross_entropy_with_logits,\n",
    "    'agg_func': tf.reduce_mean\n",
    "}\n",
    "\n",
    "params['skip_check'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:No seed specified for model 0... Defaulting to seed: 0.\n",
      "INFO:tfutils:No prefix specified for model 0... Defaulting to prefix: model_0.\n",
      "INFO:tfutils:No devices specified for model 0... Defaulting to gpus: ['/gpu:0'].\n",
      "INFO:tfutils:thres_loss not specified for model 0... Defaulting thres_loss to: 100.\n",
      "INFO:tfutils:train_loop not specified for model 0... Using default training loop.\n",
      "INFO:tfutils:validate_fist not specified for model 0... Defaulting validate_first to: True.\n",
      "INFO:tfutils:minibatch_size not specified for training data_params... Defaulting minibatch_size to: 256 (identical to the batch size).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "INFO:tfutils:Initialized from scratch first\n",
      "WARNING:tfutils:Skipping version check and info...\n",
      "INFO:tfutils:Training beginning ...\n",
      "INFO:tfutils:Saving model with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint ... \n",
      "INFO:tfutils:... done saving with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-0\n",
      "INFO:tfutils:Putting filters into <gridfs.GridFS object at 0x7ff68b27cd50> database\n",
      "INFO:tfutils:... done putting filters into database.\n",
      "INFO:tfutils:Step 1 (1132 ms) -- loss: 2.3135, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 2 (6 ms) -- loss: 2.3113, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 3 (6 ms) -- loss: 2.3176, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 4 (4 ms) -- loss: 2.3165, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 5 (19 ms) -- loss: 2.2978, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 6 (5 ms) -- loss: 2.3088, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 7 (5 ms) -- loss: 2.3048, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 8 (5 ms) -- loss: 2.3089, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 9 (5 ms) -- loss: 2.2663, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 10 (4 ms) -- loss: 2.2992, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 11 (4 ms) -- loss: 2.2743, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 12 (4 ms) -- loss: 2.2478, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 13 (6 ms) -- loss: 2.2564, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 14 (4 ms) -- loss: 2.2467, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 15 (4 ms) -- loss: 2.2532, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 16 (5 ms) -- loss: 2.1645, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 17 (5 ms) -- loss: 2.1199, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 18 (4 ms) -- loss: 2.0963, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 19 (4 ms) -- loss: 2.0229, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 20 (4 ms) -- loss: 1.9797, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 21 (5 ms) -- loss: 1.9470, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 22 (4 ms) -- loss: 1.7601, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 23 (4 ms) -- loss: 1.7661, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 24 (4 ms) -- loss: 1.7096, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 25 (3 ms) -- loss: 1.5472, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 26 (4 ms) -- loss: 1.4627, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 27 (4 ms) -- loss: 1.3538, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 28 (4 ms) -- loss: 1.2922, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 29 (4 ms) -- loss: 1.2096, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 30 (4 ms) -- loss: 1.1395, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 31 (4 ms) -- loss: 1.0367, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 32 (5 ms) -- loss: 0.9763, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 33 (4 ms) -- loss: 1.0039, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 34 (4 ms) -- loss: 0.9455, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 35 (4 ms) -- loss: 0.8088, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 36 (4 ms) -- loss: 0.7616, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 37 (4 ms) -- loss: 0.8108, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 38 (4 ms) -- loss: 0.8206, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 39 (3 ms) -- loss: 0.7165, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 40 (4 ms) -- loss: 0.7045, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 41 (4 ms) -- loss: 0.6520, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 42 (3 ms) -- loss: 0.6335, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 43 (5 ms) -- loss: 0.6749, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 44 (5 ms) -- loss: 0.6775, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 45 (4 ms) -- loss: 0.6064, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 46 (5 ms) -- loss: 0.5362, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 47 (4 ms) -- loss: 0.6187, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 48 (4 ms) -- loss: 0.5601, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 49 (8 ms) -- loss: 0.5994, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 50 (15 ms) -- loss: 0.4236, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 51 (18 ms) -- loss: 0.4574, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 52 (17 ms) -- loss: 0.4683, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 53 (46 ms) -- loss: 0.4741, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 54 (49 ms) -- loss: 0.5342, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 55 (49 ms) -- loss: 0.4031, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 56 (35 ms) -- loss: 0.3398, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 57 (30 ms) -- loss: 0.4673, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 58 (12 ms) -- loss: 0.4529, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 59 (9 ms) -- loss: 0.3878, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 60 (34 ms) -- loss: 0.5373, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 61 (117 ms) -- loss: 0.4135, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 62 (10 ms) -- loss: 0.5076, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 63 (11 ms) -- loss: 0.4276, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 64 (13 ms) -- loss: 0.4730, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 65 (12 ms) -- loss: 0.5120, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 66 (13 ms) -- loss: 0.3896, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 67 (11 ms) -- loss: 0.3257, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 68 (21 ms) -- loss: 0.3286, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 69 (16 ms) -- loss: 0.4768, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 70 (20 ms) -- loss: 0.4487, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 71 (42 ms) -- loss: 0.3862, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 72 (12 ms) -- loss: 0.4419, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 73 (15 ms) -- loss: 0.4333, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 74 (13 ms) -- loss: 0.3657, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 75 (15 ms) -- loss: 0.4662, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 76 (13 ms) -- loss: 0.3177, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 77 (13 ms) -- loss: 0.3422, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 78 (11 ms) -- loss: 0.3859, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 79 (10 ms) -- loss: 0.3282, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 80 (11 ms) -- loss: 0.4111, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 81 (16 ms) -- loss: 0.3953, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 82 (209 ms) -- loss: 0.3755, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 83 (63 ms) -- loss: 0.4229, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 84 (18 ms) -- loss: 0.4366, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 85 (32 ms) -- loss: 0.3487, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 86 (10 ms) -- loss: 0.3230, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 87 (13 ms) -- loss: 0.4579, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 88 (16 ms) -- loss: 0.3214, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 89 (95 ms) -- loss: 0.3565, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 90 (81 ms) -- loss: 0.4402, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 91 (95 ms) -- loss: 0.2995, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 92 (139 ms) -- loss: 0.2427, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 93 (14 ms) -- loss: 0.3449, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 94 (18 ms) -- loss: 0.3423, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 95 (16 ms) -- loss: 0.3949, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 96 (17 ms) -- loss: 0.1774, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 97 (21 ms) -- loss: 0.3195, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 98 (16 ms) -- loss: 0.3003, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 99 (16 ms) -- loss: 0.4582, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 100 (10 ms) -- loss: 0.3316, learning_rate: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist/b2/Momentum\n",
      "global_step\n",
      "mnist/W1/Momentum\n",
      "Variable_5\n",
      "mnist/b3/Momentum\n",
      "mnist/W3/Momentum\n",
      "mnist/b1\n",
      "mnist/b2\n",
      "mnist/b3\n",
      "Variable_3\n",
      "Variable_2\n",
      "Variable_1\n",
      "mnist/W2/Momentum\n",
      "Variable\n",
      "Variable_4\n",
      "mnist/b1/Momentum\n",
      "mnist/W3\n",
      "mnist/W2\n",
      "mnist/W1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:Saving model with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint ... \n",
      "INFO:tfutils:... done saving with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-100\n",
      "INFO:tfutils:Putting filters into <gridfs.GridFS object at 0x7ff68b27cd50> database\n",
      "INFO:tfutils:... done putting filters into database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[ObjectId('59e53168d4fdab3df1161a81'), ObjectId('59e5316bd4fdab3df1161a87')]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.train_from_params(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Now let's load the trained model from the database and test it on the validation set using TFUtils. There are 10,000 examples in the MNIST test set.\n",
    "### Fill in the blanks marked with EDIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('59e5317bd4fdab3df1161a8f'),\n",
       " u'duration': 0.3147468566894531,\n",
       " u'exp_id': u'exp1',\n",
       " u'params': {u'dont_run': False,\n",
       "  u'inter_op_parallelism_threads': 40,\n",
       "  u'load_params': {u'collname': u'simple',\n",
       "   u'dbname': u'mnist',\n",
       "   u'do_restore': True,\n",
       "   u'exp_id': u'exp1',\n",
       "   u'host': u'localhost',\n",
       "   u'port': 24444},\n",
       "  u'log_device_placement': False,\n",
       "  u'model_params': {u'cfg_final': {},\n",
       "   u'devices': [u'/gpu:0'],\n",
       "   u'func': {u'modname': u'__main__', u'objname': u'mnist_model'},\n",
       "   u'num_gpus': 1,\n",
       "   u'prefix': u'model_0',\n",
       "   u'seed': 0,\n",
       "   u'train': False},\n",
       "  u'save_params': {u'cache_filters_freq': 3000,\n",
       "   u'do_save': True,\n",
       "   u'save_filters_freq': 30000,\n",
       "   u'save_initial_filters': True,\n",
       "   u'save_metrics_freq': 100,\n",
       "   u'save_to_gfs': [],\n",
       "   u'save_valid_freq': 3000},\n",
       "  u'skip_check': True,\n",
       "  u'validation_params': {u'valid0': {u'agg_func': {u'modname': u'__main__',\n",
       "     u'objname': u'agg_mean'},\n",
       "    u'data_params': {u'batch_size': 100,\n",
       "     u'func': {u'modname': u'tfutils.data', u'objname': u'MNIST'},\n",
       "     u'group': u'test',\n",
       "     u'n_threads': 1},\n",
       "    u'num_steps': 100,\n",
       "    u'online_agg_func': {u'modname': u'__main__', u'objname': u'online_agg'},\n",
       "    u'queue_params': {u'batch_size': 100, u'queue_type': u'fifo'},\n",
       "    u'targets': {u'func': {u'modname': u'__main__', u'objname': u'top1_func'}},\n",
       "    u'valid_loop': {u'func': None}}}},\n",
       " u'saved_filters': False,\n",
       " u'step': None,\n",
       " u'validates': ObjectId('59e5316bd4fdab3df1161a87'),\n",
       " u'validation_results': {u'valid0': {u'top1': 0.8945}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = connection['mnist']\n",
    "exp = col['simple.files']\n",
    "list(exp.find())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_metric_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:No seed specified for model 0... Defaulting to seed: 0.\n",
      "INFO:tfutils:No prefix specified for model 0... Defaulting to prefix: model_0.\n",
      "INFO:tfutils:No devices specified for model 0... Defaulting to gpus: ['/gpu:0'].\n",
      "INFO:tfutils:Initialized from scratch first\n",
      "WARNING:tfutils:Skipping version check and info...\n",
      "INFO:tfutils:Loading checkpoint from mnist.simple.files\n",
      "INFO:tfutils:Cache file found at /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-100, using that to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tfutils:Skipping version check and info...\n",
      "INFO:tfutils:Loading checkpoint from mnist.simple.files\n",
      "INFO:tfutils:Cache file found at /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-100, using that to load\n",
      "INFO:tfutils:Restoring variables from record 59e5316bd4fdab3df1161a87 (step 100)...\n",
      "INFO:tfutils:Saved Vars:\n",
      "['global_step', 'mnist/W1/Momentum', 'mnist/b3/Momentum', 'mnist/b2', 'mnist/W3/Momentum', 'mnist/b1', 'Variable_5', 'mnist/b3', 'Variable_3', 'mnist/W1', 'Variable_1', 'mnist/W2/Momentum', 'Variable', 'Variable_4', 'mnist/b1/Momentum', 'mnist/W3', 'mnist/W2', 'mnist/b2/Momentum', 'Variable_2']\n",
      "INFO:tfutils:No variable mapping specified.\n",
      "INFO:tfutils:Saved shapes:\n",
      "{'Variable_4': [32, 10], 'global_step': [], 'mnist/W1/Momentum': [784, 128], 'mnist/b3/Momentum': [10], 'mnist/W3/Momentum': [32, 10], 'mnist/b1': [128], 'mnist/b2': [32], 'mnist/b3': [10], 'Variable_3': [32], 'mnist/b2/Momentum': [32], 'Variable_1': [128], 'mnist/W2/Momentum': [128, 32], 'Variable': [784, 128], 'Variable_5': [10], 'mnist/b1/Momentum': [128], 'mnist/W3': [32, 10], 'mnist/W2': [128, 32], 'mnist/W1': [784, 128], 'Variable_2': [128, 32]}\n",
      "INFO:tfutils:Restored Vars:\n",
      "[u'mnist/b1', u'mnist/b2', u'mnist/b3', u'mnist/W3', u'mnist/W2', u'mnist/W1']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-100\n",
      "INFO:tfutils:... done restoring.\n",
      "INFO:tfutils:Unrestored Vars:\n",
      "[]\n",
      "valid0: 100%|██████████| 100/100 [00:00<00:00, 321.10it/s]\n",
      "INFO:tfutils:Validation -- valid0: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8945]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:Inserting record into database.\n"
     ]
    }
   ],
   "source": [
    "def top1_func(inputs, outputs): \n",
    "    return {'top1': tf.nn.in_top_k(outputs, inputs['labels'], 1)}\n",
    "\n",
    "def online_agg(agg_res, res, step):\n",
    "    \"\"\"\n",
    "    Appends the value for each key\n",
    "    \"\"\"\n",
    "    if agg_res is None:\n",
    "        agg_res = {k: [] for k in res}\n",
    "    for k, v in res.items():\n",
    "        agg_res[k].append(v)\n",
    "    return agg_res\n",
    "\n",
    "def agg_mean(x):\n",
    "    return {k: np.mean(v) for k, v in x.items()}\n",
    "\n",
    "params = {}\n",
    "\n",
    "params['load_params'] = {\n",
    "    'host': 'localhost',\n",
    "    'port': 24444,\n",
    "    'dbname': 'mnist',\n",
    "    'collname': 'simple',\n",
    "    'exp_id': 'exp1',\n",
    "    'do_restore': True}\n",
    "\n",
    "params['validation_params'] = {'valid0': {\n",
    "    'data_params': {'func': data.MNIST,\n",
    "                    'batch_size': 100,\n",
    "                    'group': 'test',\n",
    "                    'n_threads': 1},\n",
    "    'queue_params': {'queue_type': 'fifo',\n",
    "                     'batch_size': 100},\n",
    "    'targets': {'func': top1_func},\n",
    "    'num_steps': 100,\n",
    "    'agg_func': agg_mean,\n",
    "    'online_agg_func': online_agg,}}\n",
    "\n",
    "params['model_params'] = {\n",
    "    'func': mnist_model}\n",
    "\n",
    "params['skip_check'] = True\n",
    "\n",
    "base.test_from_params(**params)\n",
    "\n",
    "# Extract record from database\n",
    "q_val = {'exp_id' : 'exp1', 'validation_results' : {'$exists' : True}, 'validates': {'$exists': True}}\n",
    "val_steps = connection['mnist']['simple.files'].find(q_val, projection = ['validation_results'])\n",
    "top1 = [val_steps[i]['validation_results']['valid0']['top1'] \n",
    "        for i in range(val_steps.count())]\n",
    "print(top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Execute the script below to load the meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('obj',\n",
       " 'rxz',\n",
       " 'rxy',\n",
       " 'ryz',\n",
       " 'ty',\n",
       " 'tz',\n",
       " 's',\n",
       " 'bg_id',\n",
       " 'size',\n",
       " 'var',\n",
       " '_id',\n",
       " 'filename',\n",
       " 'id',\n",
       " 'category',\n",
       " 'rxz_semantic',\n",
       " 'rxy_semantic',\n",
       " 'ryz_semantic')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load from tfrecords\n",
    "import cPickle\n",
    "import numpy as np\n",
    "data_path = '/datasets/neural_data/neural_data.pkl' # CHANGE THIS TO '/datasets/neural_data/neural_data.pkl'\n",
    "with open(data_path) as f:\n",
    "    data = cPickle.load(f)\n",
    "meta = data['meta']\n",
    "IT_features = data['IT']\n",
    "meta.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tabarray(['Animals', 'Boats', 'Cars', 'Chairs', 'Faces', 'Fruits',\n",
       "          'Planes', 'Tables'],\n",
       "         dtype='|S7')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(meta['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tabarray(['ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M', 'ELEPHANT_M',\n",
       "          'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA',\n",
       "          'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA',\n",
       "          'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA',\n",
       "          'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA',\n",
       "          'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA',\n",
       "          'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA',\n",
       "          'GORILLA', 'GORILLA', 'GORILLA', 'GORILLA', 'LIONESS', 'LIONESS',\n",
       "          'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS',\n",
       "          'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS',\n",
       "          'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS',\n",
       "          'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS',\n",
       "          'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS',\n",
       "          'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS', 'LIONESS',\n",
       "          'LIONESS', 'LIONESS', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L',\n",
       "          'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L',\n",
       "          'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L',\n",
       "          'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L',\n",
       "          'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L',\n",
       "          'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L',\n",
       "          'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L',\n",
       "          'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L', 'TURTLE_L',\n",
       "          'TURTLE_L', 'TURTLE_L', 'bear', 'bear', 'bear', 'bear', 'bear',\n",
       "          'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear',\n",
       "          'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear',\n",
       "          'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear',\n",
       "          'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear',\n",
       "          'bear', 'bear', 'bear', 'blCow', 'blCow', 'blCow', 'blCow',\n",
       "          'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow',\n",
       "          'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow',\n",
       "          'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow',\n",
       "          'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow',\n",
       "          'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow', 'blCow',\n",
       "          'blCow', 'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug',\n",
       "          'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug',\n",
       "          'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug',\n",
       "          'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug',\n",
       "          'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug',\n",
       "          'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug',\n",
       "          'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug',\n",
       "          'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug', 'breed_pug',\n",
       "          'breed_pug', 'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog',\n",
       "          'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog',\n",
       "          'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog',\n",
       "          'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog',\n",
       "          'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog',\n",
       "          'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog',\n",
       "          'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog',\n",
       "          'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog', 'hedgehog',\n",
       "          'hedgehog'],\n",
       "         dtype='|S24')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[(meta['category'] == 'Animals') & (meta['var'] == 'V6')]['obj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Select all files with 'Animals' or 'Cars' with a rotation in the xy-plane of more than 45 degrees and print how many there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = meta[(meta['category'] == 'Cars') & (meta['rxz'] > 45)]['filename']\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.) Select all objects with 'GORILLA' that either have a variation level of 'V0' or a size 's' bigger 1 or both, and print the object names, their sizes 's' and variation levels as tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objects = meta[(meta['obj'] == 'GORILLA') & ((meta['var'] == 'V0') | (meta['s'] > 1))]\n",
    "tuples = [(obj['obj'], obj['s'], obj['var']) for obj in objects]\n",
    "for tpl in tuples:\n",
    "    print(tpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.) Perform a 8-way classification on the categories, using 20 splits, a 'svm.LinearSVC' classifier a 'C' of 5e-3 on variation level 'V0' for train and test.\n",
    "### Fill in the blanks marked with EDIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't import separate mcc package\n",
      "Can't import asgd.\n",
      "Can't import scikits stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'IT_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f984f79d64d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m }\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Execute classification experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_metric_base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIT_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_eval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Print results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IT_features' is not defined"
     ]
    }
   ],
   "source": [
    "from dldata.metrics.utils import compute_metric_base\n",
    "# Definition of classification experiment\n",
    "category_eval_spec = {\n",
    "    'npc_train': None,\n",
    "    'npc_test': 2,\n",
    "    'num_splits': 20,\n",
    "    'npc_validate': 0,\n",
    "    'metric_screen': 'classifier',\n",
    "    'metric_labels': None,\n",
    "    'metric_kwargs': {'model_type': 'svm.LinearSVC',\n",
    "                      'model_kwargs': {'C':5e-3}\n",
    "                     },\n",
    "    'labelfunc': 'category',\n",
    "    'train_q': {'var': ['V0']},\n",
    "    'test_q': {'var': ['V0']},\n",
    "    'split_by': 'obj'\n",
    "}\n",
    "# Execute classification experiment\n",
    "res = compute_metric_base(IT_features, meta, category_eval_spec)\n",
    "\n",
    "# Print results\n",
    "print('Overall accuracy of IT features on 8-way classification task: %.2f%%' % \\\n",
    "      ((np.array(res['result_summary']['accbal']).mean(0) - 0.5) * 2.0 * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.) Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "m = fig.gca().matshow(np.array(res['result_summary']['cms']).mean(2))\n",
    "plt.xticks(range(8), res['result_summary']['labelset'])\n",
    "plt.yticks(range(8), res['result_summary']['labelset'])\n",
    "plt.colorbar(m)\n",
    "plt.title('8-way categorization task - across category confusion matrix')\n",
    "ax = plt.gca()\n",
    "ax.xaxis.tick_bottom()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
