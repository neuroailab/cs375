{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-2, 2, 101)[np.random.RandomState(0).permutation(101)]\n",
    "y = x ** 3 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Insert x and y into the database \"tasks\", collection \"polyfunction\" on host \"localhost\", port \"24444\", read it out again in sorted order print \"x\" and plot \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f8294050248>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = 24444\n",
    "host = 'localhost'\n",
    "connection = pm.MongoClient(port = port, host = host)\n",
    "\n",
    "entries = []\n",
    "for i in range(101):\n",
    "    entries.append({'x': x[i], 'y': y[i]})\n",
    "connection['tasks']['polyfunction'].insert_many(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -1.96, -1.96, -1.96, -1.96, -1.96, -1.96, -1.92, -1.92, -1.92, -1.92, -1.92, -1.92, -1.88, -1.88, -1.88, -1.88, -1.88, -1.88, -1.84, -1.84, -1.84, -1.84, -1.84, -1.84, -1.8, -1.8, -1.8, -1.8, -1.8, -1.8, -1.76, -1.76, -1.76, -1.76, -1.76, -1.76, -1.72, -1.72, -1.72, -1.72, -1.72, -1.72, -1.68, -1.68, -1.68, -1.68, -1.68, -1.68, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6, -1.6, -1.6, -1.6, -1.6, -1.6, -1.56, -1.56, -1.56, -1.56, -1.56, -1.56, -1.52, -1.52, -1.52, -1.52, -1.52, -1.52, -1.48, -1.48, -1.48, -1.48, -1.48, -1.48, -1.44, -1.44, -1.44, -1.44, -1.44, -1.44, -1.4, -1.4, -1.4, -1.4, -1.4, -1.4, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.28, -1.28, -1.28, -1.28, -1.28, -1.28, -1.24, -1.24, -1.24, -1.24, -1.24, -1.24, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.12, -1.12, -1.12, -1.12, -1.12, -1.12, -1.08, -1.08, -1.08, -1.08, -1.08, -1.08, -1.04, -1.04, -1.04, -1.04, -1.04, -1.04, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.96, -0.96, -0.96, -0.96, -0.96, -0.96, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.76, -0.76, -0.76, -0.76, -0.76, -0.76, -0.72, -0.72, -0.72, -0.72, -0.72, -0.72, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.56, -0.56, -0.56, -0.56, -0.56, -0.56, -0.52, -0.52, -0.52, -0.52, -0.52, -0.52, -0.48, -0.48, -0.48, -0.48, -0.48, -0.48, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.28, -0.28, -0.28, -0.28, -0.28, -0.28, -0.24, -0.24, -0.24, -0.24, -0.24, -0.24, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.04, 1.04, 1.04, 1.04, 1.04, 1.04, 1.08, 1.08, 1.08, 1.08, 1.08, 1.08, 1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.44, 1.44, 1.44, 1.44, 1.44, 1.44, 1.48, 1.48, 1.48, 1.48, 1.48, 1.48, 1.52, 1.52, 1.52, 1.52, 1.52, 1.52, 1.56, 1.56, 1.56, 1.56, 1.56, 1.56, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.88, 1.88, 1.88, 1.88, 1.88, 1.88, 1.92, 1.92, 1.92, 1.92, 1.92, 1.92, 1.96, 1.96, 1.96, 1.96, 1.96, 1.96, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRJKMil1EJMmo2EVEksz/AyLaSo8TBUuJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82c23af3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entries = connection['tasks']['polyfunction'].find({'x': {'$exists' : True}}, projection=['x', 'y']).sort([('x',pm.ASCENDING)])\n",
    "x = [entry['x'] for entry in entries]\n",
    "print(x)\n",
    "entries = connection['tasks']['polyfunction'].find({'x': {'$exists' : True}}, projection=['x', 'y']).sort([('x',pm.ASCENDING)])\n",
    "y = [entry['y'] for entry in entries]\n",
    "plt.plot(x,y)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Run the script below which trains a MLP for the 10-way MNIST classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:No seed specified for model 0... Defaulting to seed: 0.\n",
      "INFO:tfutils:No prefix specified for model 0... Defaulting to prefix: model_0.\n",
      "INFO:tfutils:No devices specified for model 0... Defaulting to gpus: ['/gpu:0'].\n",
      "INFO:tfutils:thres_loss not specified for model 0... Defaulting thres_loss to: 100.\n",
      "INFO:tfutils:train_loop not specified for model 0... Using default training loop.\n",
      "INFO:tfutils:validate_fist not specified for model 0... Defaulting validate_first to: True.\n",
      "INFO:tfutils:minibatch_size not specified for training data_params... Defaulting minibatch_size to: 256 (identical to the batch size).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "INFO:tfutils:Initialized from scratch first\n",
      "WARNING:tfutils:Skipping version check and info...\n",
      "INFO:tfutils:Training beginning ...\n",
      "INFO:tfutils:Saving model with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint ... \n",
      "INFO:tfutils:... done saving with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-0\n",
      "INFO:tfutils:Putting filters into <gridfs.GridFS object at 0x7f8238e308d0> database\n",
      "INFO:tfutils:... done putting filters into database.\n",
      "INFO:tfutils:Step 1 (217 ms) -- loss: 2.3540, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 2 (4 ms) -- loss: 2.3187, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 3 (5 ms) -- loss: 2.3153, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 4 (4 ms) -- loss: 2.3622, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 5 (4 ms) -- loss: 2.3368, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 6 (4 ms) -- loss: 2.2913, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 7 (4 ms) -- loss: 2.2774, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 8 (4 ms) -- loss: 2.2637, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 9 (4 ms) -- loss: 2.2709, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 10 (4 ms) -- loss: 2.2766, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 11 (5 ms) -- loss: 2.2565, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 12 (4 ms) -- loss: 2.2123, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 13 (4 ms) -- loss: 2.1964, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 14 (4 ms) -- loss: 2.1676, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 15 (5 ms) -- loss: 2.1879, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 16 (4 ms) -- loss: 2.1312, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 17 (4 ms) -- loss: 2.0751, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 18 (4 ms) -- loss: 2.0007, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 19 (4 ms) -- loss: 1.9781, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 20 (4 ms) -- loss: 1.8743, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 21 (12 ms) -- loss: 1.7569, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 22 (4 ms) -- loss: 1.7759, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 23 (4 ms) -- loss: 1.6565, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 24 (4 ms) -- loss: 1.5812, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 25 (4 ms) -- loss: 1.5022, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 26 (4 ms) -- loss: 1.3919, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 27 (4 ms) -- loss: 1.3035, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 28 (4 ms) -- loss: 1.2691, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 29 (4 ms) -- loss: 1.1774, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 30 (4 ms) -- loss: 1.1745, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 31 (4 ms) -- loss: 1.0017, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 32 (4 ms) -- loss: 1.0451, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 33 (4 ms) -- loss: 0.9366, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 34 (5 ms) -- loss: 0.8012, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 35 (4 ms) -- loss: 0.8771, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 36 (4 ms) -- loss: 0.7857, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 37 (4 ms) -- loss: 0.8178, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 38 (4 ms) -- loss: 0.7163, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 39 (4 ms) -- loss: 0.7183, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 40 (4 ms) -- loss: 0.5977, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 41 (5 ms) -- loss: 0.6859, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 42 (4 ms) -- loss: 0.6883, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 43 (4 ms) -- loss: 0.6409, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 44 (4 ms) -- loss: 0.6481, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 45 (4 ms) -- loss: 0.6425, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 46 (4 ms) -- loss: 0.6197, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 47 (4 ms) -- loss: 0.5396, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 48 (4 ms) -- loss: 0.5591, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 49 (4 ms) -- loss: 0.4985, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 50 (4 ms) -- loss: 0.5687, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 51 (4 ms) -- loss: 0.5559, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 52 (4 ms) -- loss: 0.5616, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 53 (4 ms) -- loss: 0.4875, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 54 (4 ms) -- loss: 0.4846, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 55 (4 ms) -- loss: 0.4745, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 56 (4 ms) -- loss: 0.3618, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 57 (4 ms) -- loss: 0.5077, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 58 (4 ms) -- loss: 0.4527, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 59 (4 ms) -- loss: 0.4494, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 60 (4 ms) -- loss: 0.5083, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 61 (4 ms) -- loss: 0.3624, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 62 (4 ms) -- loss: 0.4165, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 63 (5 ms) -- loss: 0.4897, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 64 (4 ms) -- loss: 0.3468, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 65 (4 ms) -- loss: 0.4269, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 66 (4 ms) -- loss: 0.4275, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 67 (4 ms) -- loss: 0.3603, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 68 (5 ms) -- loss: 0.4243, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 69 (4 ms) -- loss: 0.3561, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 70 (4 ms) -- loss: 0.4055, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 71 (4 ms) -- loss: 0.3365, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 72 (4 ms) -- loss: 0.6179, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 73 (4 ms) -- loss: 0.4800, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 74 (4 ms) -- loss: 0.5103, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 75 (4 ms) -- loss: 0.3547, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 76 (4 ms) -- loss: 0.3905, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 77 (4 ms) -- loss: 0.3387, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 78 (4 ms) -- loss: 0.2846, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 79 (4 ms) -- loss: 0.4095, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 80 (4 ms) -- loss: 0.4155, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 81 (4 ms) -- loss: 0.3229, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 82 (4 ms) -- loss: 0.3925, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 83 (4 ms) -- loss: 0.4379, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 84 (4 ms) -- loss: 0.3070, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 85 (4 ms) -- loss: 0.4175, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 86 (4 ms) -- loss: 0.4020, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 87 (4 ms) -- loss: 0.3822, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 88 (5 ms) -- loss: 0.3786, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 89 (4 ms) -- loss: 0.3596, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 90 (4 ms) -- loss: 0.3174, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 91 (4 ms) -- loss: 0.4147, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 92 (4 ms) -- loss: 0.3833, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 93 (5 ms) -- loss: 0.3841, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 94 (5 ms) -- loss: 0.3146, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 95 (4 ms) -- loss: 0.3799, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 96 (4 ms) -- loss: 0.2720, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 97 (5 ms) -- loss: 0.2649, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 98 (4 ms) -- loss: 0.3745, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 99 (4 ms) -- loss: 0.3841, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 100 (4 ms) -- loss: 0.4057, learning_rate: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist/b2/Momentum\n",
      "global_step\n",
      "mnist/W1/Momentum\n",
      "Variable_5\n",
      "mnist/b3/Momentum\n",
      "mnist/W3/Momentum\n",
      "mnist/b1\n",
      "mnist/b2\n",
      "mnist/b3\n",
      "Variable_3\n",
      "Variable_2\n",
      "Variable_1\n",
      "mnist/W2/Momentum\n",
      "Variable\n",
      "Variable_4\n",
      "mnist/b1/Momentum\n",
      "mnist/W3\n",
      "mnist/W2\n",
      "mnist/W1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:Saving model with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint ... \n",
      "INFO:tfutils:... done saving with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-100\n",
      "INFO:tfutils:Putting filters into <gridfs.GridFS object at 0x7f8238e308d0> database\n",
      "INFO:tfutils:... done putting filters into database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[ObjectId('59deb64ad4fdab0d890a6d8d'), ObjectId('59deb64bd4fdab0d890a6d93')]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import division\n",
    "from tfutils import base, data, optimizer, utils\n",
    "\n",
    "# delete exp1\n",
    "connection['mnist']['simple.files'].delete_many({'exp_id' : 'exp1'})\n",
    "\n",
    "def mnist_model(inputs, train=True, **kwargs):\n",
    "    # trainable variables randomly initialized\n",
    "    with tf.variable_scope(\"mnist\"):\n",
    "        W1 = tf.get_variable('W1', [784,128], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b1 = tf.get_variable('b1', [128], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        W2 = tf.get_variable('W2', [128,32], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b2 = tf.get_variable('b2', [32], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        W3 = tf.get_variable('W3', [32,10], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b3 = tf.get_variable('b3', [10], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        \n",
    "        # hidden layers\n",
    "        h1 = tf.nn.sigmoid(tf.matmul(inputs['images'], W1) + b1, name='hidden1')\n",
    "        h2 = tf.nn.sigmoid(tf.matmul(h1, W2) + b2, name='hidden2')\n",
    "        # output\n",
    "        output = tf.matmul(h2, W3) + b3\n",
    "\n",
    "    return output, {}\n",
    "\n",
    "params = {}\n",
    "\n",
    "params['load_params'] = {\n",
    "    'do_restore': False}\n",
    "\n",
    "params['save_params'] = {\n",
    "    'host': 'localhost',\n",
    "    'port': 24444,\n",
    "    'dbname': 'mnist',\n",
    "    'collname': 'simple',\n",
    "    'exp_id': 'exp1',\n",
    "    'save_valid_freq': 200,\n",
    "    'save_filters_freq': 100,\n",
    "    'cache_filters_freq': 100}\n",
    "\n",
    "params['train_params'] = {\n",
    "    'data_params': {'func': data.MNIST,\n",
    "                    'batch_size': 256,\n",
    "                    'group': 'train',\n",
    "                    'n_threads': 1},\n",
    "    'queue_params': {'queue_type': 'random',\n",
    "                     'batch_size': 256},\n",
    "    'num_steps': 100}\n",
    "\n",
    "params['model_params'] = {\n",
    "    'func': mnist_model} \n",
    "\n",
    "params['learning_rate_params'] = {\n",
    "    'learning_rate': 0.5,\n",
    "    'decay_steps': 500,\n",
    "    'decay_rate': 0.95,\n",
    "    'staircase': True}\n",
    "\n",
    "params['optimizer_params'] = {\n",
    "    'func': optimizer.ClipOptimizer,\n",
    "    'optimizer_class': tf.train.MomentumOptimizer,\n",
    "    'momentum': 0.9,\n",
    "    'clip': True,\n",
    "}\n",
    "\n",
    "params['loss_params'] = {\n",
    "    'targets': ['labels'],\n",
    "    'loss_per_case_func': tf.nn.sparse_softmax_cross_entropy_with_logits,\n",
    "    'agg_func': tf.reduce_mean\n",
    "}\n",
    "\n",
    "params['skip_check'] = True\n",
    "\n",
    "base.train_from_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Now let's load the trained model from the database and test it on the validation set using TFUtils. There are 10,000 examples in the MNIST test set.\n",
    "### Fill in the blanks marked with EDIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:No seed specified for model 0... Defaulting to seed: 0.\n",
      "INFO:tfutils:No prefix specified for model 0... Defaulting to prefix: model_0.\n",
      "INFO:tfutils:No devices specified for model 0... Defaulting to gpus: ['/gpu:0'].\n",
      "INFO:tfutils:Initialized from scratch first\n",
      "WARNING:tfutils:Skipping version check and info...\n",
      "INFO:tfutils:Loading checkpoint from mnist.simple.files\n",
      "INFO:tfutils:Cache file found at /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-100, using that to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in_top_k() takes at least 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ef5946807de5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'skip_check'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_from_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# Extract record from database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/python_packages/tfutils/tfutils/base.pyc\u001b[0m in \u001b[0;36mtest_from_params\u001b[1;34m(load_params, model_params, validation_params, log_device_placement, save_params, dont_run, skip_check, inter_op_parallelism_threads)\u001b[0m\n\u001b[0;32m    933\u001b[0m                                                        \u001b[0mcfg_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                                                        \u001b[0mqueue_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_queue_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                                                        **param)\n\u001b[0m\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m             \u001b[1;31m# tf.get_variable_scope().reuse_variables()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/python_packages/tfutils/tfutils/base.pyc\u001b[0m in \u001b[0;36mget_valid_targets_dict\u001b[1;34m(validation_params, model_params, loss_params, queue_params, cfg_final, **params)\u001b[0m\n\u001b[0;32m   1409\u001b[0m             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m         validation_params[vtarg], valid_targets_dict[vtarg] = get_validation_target(vinputs, voutputs,\n\u001b[1;32m-> 1411\u001b[1;33m                                                                                     **validation_params[vtarg])\n\u001b[0m\u001b[0;32m   1412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalid_targets_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/python_packages/tfutils/tfutils/base.pyc\u001b[0m in \u001b[0;36mget_validation_target\u001b[1;34m(vinputs, voutputs, default_target_func, default_target_params, default_loop_func, default_loop_params, agg_func, online_agg_func, **validation_params)\u001b[0m\n\u001b[0;32m   1429\u001b[0m     \u001b[0mtarget_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'targets'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_target_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1430\u001b[0m     \u001b[0mtarget_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'func'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_target_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1431\u001b[1;33m     \u001b[0mvtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvinputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtarget_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1432\u001b[0m     \u001b[0mtarget_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'func'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m     \u001b[0mvalidation_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'targets'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ef5946807de5>\u001b[0m in \u001b[0;36mtop1_func\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'top1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_top_k\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in_top_k() takes at least 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "def top1_func(inputs, outputs): \n",
    "    \"\"\"\n",
    "    Computes the top1 accuracy with tf.nn.in_top_k\n",
    "    predictions = outputs\n",
    "    targets = inputs['labels']\n",
    "    \"\"\"\n",
    "    res = {'top1': tf.nn.in_top_k(outputs,inputs['labels'])}\n",
    "    return res\n",
    "\n",
    "def online_agg(agg_res, res, step):\n",
    "    \"\"\"\n",
    "    Appends the value for each key\n",
    "    \"\"\"\n",
    "    if agg_res is None:\n",
    "        agg_res = {k: [] for k in res}\n",
    "    for k, v in res.items():\n",
    "        agg_res[k].append(v)\n",
    "    return agg_res\n",
    "\n",
    "def agg_mean(x):\n",
    "    \"\"\"\n",
    "    Takes the mean of the aggregated results x\n",
    "    \"\"\"\n",
    "    return {k: np.mean(v) for k, v in x.items()}\n",
    "\n",
    "params = {}\n",
    "        \n",
    "params['load_params'] = {\n",
    "    'host': 'localhost',\n",
    "    'port': 24444,\n",
    "    'dbname': 'mnist',\n",
    "    'collname': 'simple',\n",
    "    'exp_id': 'exp1',\n",
    "    'do_restore': True}\n",
    "\n",
    "params['validation_params'] = {'valid0': {\n",
    "    'data_params': {'func': data.MNIST,\n",
    "                    'batch_size': 256,\n",
    "                    'group': 'train',\n",
    "                    'n_threads': 1},\n",
    "    'queue_params': {'queue_type': 'random',\n",
    "                     'batch_size': 256},\n",
    "    'targets': {'func': top1_func},\n",
    "    'num_steps': 100,\n",
    "    'agg_func': agg_mean,\n",
    "    'online_agg_func': online_agg,}}\n",
    "\n",
    "params['model_params'] = {\n",
    "    'func': mnist_model}\n",
    "\n",
    "params['skip_check'] = True\n",
    "\n",
    "base.test_from_params(**params)\n",
    "\n",
    "# Extract record from database\n",
    "q_val = {'exp_id' : EDIT, 'validation_results' : {'$exists' : True}, 'validates': {'$exists': True}}\n",
    "val_steps = connection[EDIT]['EDIT.files'].find(EDIT)\n",
    "top1 = [val_steps[i][EDIT][EDIT][EDIT] \n",
    "        for i in range(val_steps.count())]\n",
    "print(top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Execute the script below to load the meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('obj',\n",
       " 'rxz',\n",
       " 'rxy',\n",
       " 'ryz',\n",
       " 'ty',\n",
       " 'tz',\n",
       " 's',\n",
       " 'bg_id',\n",
       " 'size',\n",
       " 'var',\n",
       " '_id',\n",
       " 'filename',\n",
       " 'id',\n",
       " 'category',\n",
       " 'rxz_semantic',\n",
       " 'rxy_semantic',\n",
       " 'ryz_semantic')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load from tfrecords\n",
    "import cPickle\n",
    "import numpy as np\n",
    "data_path = '/datasets/neural_data/neural_data.pkl'\n",
    "with open(data_path) as f:\n",
    "    data = cPickle.load(f)\n",
    "meta = data['meta']\n",
    "IT_features = data['IT']\n",
    "meta.dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Select all files with 'Animals' or 'Cars' with a rotation in the xy-plane of more than 45 degrees and print how many there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tabarray(['Apple_Fruit_obj', 'Apricot_obj', 'BAHRAIN', 'Beetle', 'CGTG_L',\n",
       "          'DTUG_L', 'ELEPHANT_M', 'GORILLA', 'LIONESS', 'MQUEEN_L',\n",
       "          'Peach_obj', 'Pear_obj', 'SISTER_L', 'Strawberry_obj',\n",
       "          'TURTLE_L', '_001', '_004', '_008', '_010', '_011', '_014',\n",
       "          '_01_Airliner_2jetEngines', '_031', '_033', '_05_future', '_08',\n",
       "          '_10', '_11', '_12', '_18', '_19_flyingBoat', '_37', '_38',\n",
       "          '_44', 'alfa155', 'astra', 'bear', 'blCow', 'bmw325', 'bora_a',\n",
       "          'breed_pug', 'celica', 'clio', 'cruiser', 'f16', 'face0001',\n",
       "          'face0002', 'face0003', 'face0004', 'face0005', 'face0006',\n",
       "          'face0007', 'face0008', 'hedgehog', 'junkers88', 'mig29',\n",
       "          'motoryacht', 'raspberry_obj', 'rdbarren', 'sopwith', 'support',\n",
       "          'walnut_obj', 'watermelon_obj', 'z3'],\n",
       "         dtype='|S24')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(meta['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(meta['obj']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tabarray(['Beetle', 'alfa155', 'astra', 'bmw325', 'bora_a', 'celica',\n",
       "          'clio', 'z3'],\n",
       "         dtype='|S24')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(meta[meta['category']=='Cars']['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.) Select all objects with 'GORILLA' that either have a variation level of 'V0' or a size 's' bigger 1 or both, and print the object names, their sizes 's' and variation levels as tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.) Perform a 8-way classification on the categories, using 20 splits, a 'svm.LinearSVC' classifier a 'C' of 5e-3 on variation level 'V0' for train and test.\n",
    "### Fill in the blanks marked with EDIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dldata.metrics.utils import compute_metric_base\n",
    "# Definition of classification experiment\n",
    "category_eval_spec = {\n",
    "    'npc_train': None,\n",
    "    'npc_test': 2,\n",
    "    'num_splits': EDIT,\n",
    "    'npc_validate': 0,\n",
    "    'metric_screen': EDIT,\n",
    "    'metric_labels': None,\n",
    "    'metric_kwargs': {'model_type': EDIT,\n",
    "                      'model_kwargs': {EDIT}\n",
    "                     },\n",
    "    'labelfunc': EDIT,\n",
    "    'train_q': {EDIT},\n",
    "    'test_q': {EDIT},\n",
    "    'split_by': 'obj'\n",
    "}\n",
    "# Execute classification experiment\n",
    "res = compute_metric_base(IT_features, meta, category_eval_spec)\n",
    "\n",
    "# Print results\n",
    "print('Overall accuracy of IT features on 8-way classification task: %.2f%%' % \\\n",
    "      ((np.array(res['result_summary']['accbal']).mean(0) - 0.5) * 2.0 * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.) Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cms = res['result_summary']['cms']).mean(2)\n",
    "axis_labels = res['result_summary']['labelset']\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
