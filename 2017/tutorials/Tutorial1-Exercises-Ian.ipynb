{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-2, 2, 101)[np.random.RandomState(0).permutation(101)]\n",
    "y = x ** 3 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Insert x and y into the database \"tasks\", collection \"polyfunction\" on host \"localhost\", port \"24444\", read it out again in sorted order print \"x\" and plot \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fb442805050>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = 24444\n",
    "host = 'localhost'\n",
    "connection = pm.MongoClient(port = port, host = host)\n",
    "\n",
    "entries = []\n",
    "for i in range(101):\n",
    "    entries.append({'x': x[i], 'y': y[i]})\n",
    "connection['tasks']['polyfunction'].insert_many(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -1.96, -1.96, -1.96, -1.96, -1.96, -1.96, -1.96, -1.96, -1.96, -1.92, -1.92, -1.92, -1.92, -1.92, -1.92, -1.92, -1.92, -1.92, -1.88, -1.88, -1.88, -1.88, -1.88, -1.88, -1.88, -1.88, -1.88, -1.84, -1.84, -1.84, -1.84, -1.84, -1.84, -1.84, -1.84, -1.84, -1.8, -1.8, -1.8, -1.8, -1.8, -1.8, -1.8, -1.8, -1.8, -1.76, -1.76, -1.76, -1.76, -1.76, -1.76, -1.76, -1.76, -1.76, -1.72, -1.72, -1.72, -1.72, -1.72, -1.72, -1.72, -1.72, -1.72, -1.68, -1.68, -1.68, -1.68, -1.68, -1.68, -1.68, -1.68, -1.68, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6400000000000001, -1.6, -1.6, -1.6, -1.6, -1.6, -1.6, -1.6, -1.6, -1.6, -1.56, -1.56, -1.56, -1.56, -1.56, -1.56, -1.56, -1.56, -1.56, -1.52, -1.52, -1.52, -1.52, -1.52, -1.52, -1.52, -1.52, -1.52, -1.48, -1.48, -1.48, -1.48, -1.48, -1.48, -1.48, -1.48, -1.48, -1.44, -1.44, -1.44, -1.44, -1.44, -1.44, -1.44, -1.44, -1.44, -1.4, -1.4, -1.4, -1.4, -1.4, -1.4, -1.4, -1.4, -1.4, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3599999999999999, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.3199999999999998, -1.28, -1.28, -1.28, -1.28, -1.28, -1.28, -1.28, -1.28, -1.28, -1.24, -1.24, -1.24, -1.24, -1.24, -1.24, -1.24, -1.24, -1.24, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.1600000000000001, -1.12, -1.12, -1.12, -1.12, -1.12, -1.12, -1.12, -1.12, -1.12, -1.08, -1.08, -1.08, -1.08, -1.08, -1.08, -1.08, -1.08, -1.08, -1.04, -1.04, -1.04, -1.04, -1.04, -1.04, -1.04, -1.04, -1.04, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.96, -0.96, -0.96, -0.96, -0.96, -0.96, -0.96, -0.96, -0.96, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.9199999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8799999999999999, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8400000000000001, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.76, -0.76, -0.76, -0.76, -0.76, -0.76, -0.76, -0.76, -0.76, -0.72, -0.72, -0.72, -0.72, -0.72, -0.72, -0.72, -0.72, -0.72, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6799999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.6399999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.5999999999999999, -0.56, -0.56, -0.56, -0.56, -0.56, -0.56, -0.56, -0.56, -0.56, -0.52, -0.52, -0.52, -0.52, -0.52, -0.52, -0.52, -0.52, -0.52, -0.48, -0.48, -0.48, -0.48, -0.48, -0.48, -0.48, -0.48, -0.48, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.43999999999999995, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3999999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.3599999999999999, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.32000000000000006, -0.28, -0.28, -0.28, -0.28, -0.28, -0.28, -0.28, -0.28, -0.28, -0.24, -0.24, -0.24, -0.24, -0.24, -0.24, -0.24, -0.24, -0.24, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.19999999999999996, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.15999999999999992, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.11999999999999988, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.08000000000000007, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, -0.040000000000000036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.08000000000000007, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.1200000000000001, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.16000000000000014, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.20000000000000018, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.2400000000000002, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.28000000000000025, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.31999999999999984, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3599999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.3999999999999999, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.43999999999999995, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6400000000000001, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.6800000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7200000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.7600000000000002, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8000000000000003, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8399999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.8799999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.9199999999999999, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.04, 1.04, 1.04, 1.04, 1.04, 1.04, 1.04, 1.04, 1.04, 1.08, 1.08, 1.08, 1.08, 1.08, 1.08, 1.08, 1.08, 1.08, 1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.1600000000000001, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2000000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2400000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.2800000000000002, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3200000000000003, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.3599999999999999, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.44, 1.44, 1.44, 1.44, 1.44, 1.44, 1.44, 1.44, 1.44, 1.48, 1.48, 1.48, 1.48, 1.48, 1.48, 1.48, 1.48, 1.48, 1.52, 1.52, 1.52, 1.52, 1.52, 1.52, 1.52, 1.52, 1.52, 1.56, 1.56, 1.56, 1.56, 1.56, 1.56, 1.56, 1.56, 1.56, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6400000000000001, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.6800000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7200000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.7600000000000002, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8000000000000003, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.8399999999999999, 1.88, 1.88, 1.88, 1.88, 1.88, 1.88, 1.88, 1.88, 1.88, 1.92, 1.92, 1.92, 1.92, 1.92, 1.92, 1.92, 1.92, 1.92, 1.96, 1.96, 1.96, 1.96, 1.96, 1.96, 1.96, 1.96, 1.96, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRJKMil1EJMmo2EVEksz/AyLaSo8TBUuJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4763afe90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entries = connection['tasks']['polyfunction'].find({'x': {'$exists' : True}}, projection=['x', 'y']).sort([('x',pm.ASCENDING)])\n",
    "x = [entry['x'] for entry in entries]\n",
    "print(x)\n",
    "entries = connection['tasks']['polyfunction'].find({'x': {'$exists' : True}}, projection=['x', 'y']).sort([('x',pm.ASCENDING)])\n",
    "y = [entry['y'] for entry in entries]\n",
    "plt.plot(x,y)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Run the script below which trains a MLP for the 10-way MNIST classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:No seed specified for model 0... Defaulting to seed: 0.\n",
      "INFO:tfutils:No prefix specified for model 0... Defaulting to prefix: model_0.\n",
      "INFO:tfutils:No devices specified for model 0... Defaulting to gpus: ['/gpu:0'].\n",
      "INFO:tfutils:thres_loss not specified for model 0... Defaulting thres_loss to: 100.\n",
      "INFO:tfutils:train_loop not specified for model 0... Using default training loop.\n",
      "INFO:tfutils:validate_fist not specified for model 0... Defaulting validate_first to: True.\n",
      "INFO:tfutils:minibatch_size not specified for training data_params... Defaulting minibatch_size to: 256 (identical to the batch size).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /python_packages/tfutils/tfutils/optimizer.py:100: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "INFO:tfutils:Initialized from scratch first\n",
      "WARNING:tfutils:Skipping version check and info...\n",
      "INFO:tfutils:Training beginning ...\n",
      "INFO:tfutils:Saving model with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint ... \n",
      "INFO:tfutils:... done saving with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-0\n",
      "INFO:tfutils:Putting filters into <gridfs.GridFS object at 0x7fb3e9d95cd0> database\n",
      "INFO:tfutils:... done putting filters into database.\n",
      "INFO:tfutils:Step 1 (752 ms) -- loss: 2.3565, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 2 (12 ms) -- loss: 2.3163, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 3 (48 ms) -- loss: 2.3019, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 4 (220 ms) -- loss: 2.3848, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 5 (19 ms) -- loss: 2.2922, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 6 (47 ms) -- loss: 2.3114, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 7 (9 ms) -- loss: 2.3031, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 8 (10 ms) -- loss: 2.2900, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 9 (16 ms) -- loss: 2.2939, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 10 (70 ms) -- loss: 2.2986, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 11 (118 ms) -- loss: 2.2480, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 12 (104 ms) -- loss: 2.2436, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 13 (91 ms) -- loss: 2.2177, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 14 (26 ms) -- loss: 2.2184, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 15 (18 ms) -- loss: 2.2434, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 16 (18 ms) -- loss: 2.1634, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 17 (18 ms) -- loss: 2.0871, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 18 (18 ms) -- loss: 2.0728, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 19 (16 ms) -- loss: 2.0223, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 20 (17 ms) -- loss: 2.0132, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 21 (13 ms) -- loss: 1.9186, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 22 (4 ms) -- loss: 1.8575, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 23 (4 ms) -- loss: 1.8057, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 24 (4 ms) -- loss: 1.6877, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 25 (5 ms) -- loss: 1.5980, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 26 (5 ms) -- loss: 1.5199, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 27 (4 ms) -- loss: 1.5290, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 28 (4 ms) -- loss: 1.4327, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 29 (4 ms) -- loss: 1.2834, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 30 (5 ms) -- loss: 1.2967, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 31 (5 ms) -- loss: 1.2626, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 32 (5 ms) -- loss: 1.1891, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 33 (5 ms) -- loss: 1.1770, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 34 (5 ms) -- loss: 1.0314, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 35 (4 ms) -- loss: 0.9669, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 36 (4 ms) -- loss: 0.9551, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 37 (4 ms) -- loss: 0.9800, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 38 (4 ms) -- loss: 0.8389, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 39 (4 ms) -- loss: 0.8956, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 40 (4 ms) -- loss: 0.8133, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 41 (4 ms) -- loss: 0.7253, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 42 (4 ms) -- loss: 0.8852, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 43 (4 ms) -- loss: 0.8016, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 44 (4 ms) -- loss: 0.7244, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 45 (5 ms) -- loss: 0.6006, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 46 (4 ms) -- loss: 0.6600, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 47 (4 ms) -- loss: 0.6627, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 48 (4 ms) -- loss: 0.5696, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 49 (4 ms) -- loss: 0.6701, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 50 (4 ms) -- loss: 0.5864, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 51 (5 ms) -- loss: 0.6496, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 52 (4 ms) -- loss: 0.5113, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 53 (4 ms) -- loss: 0.5323, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 54 (4 ms) -- loss: 0.5314, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 55 (5 ms) -- loss: 0.5320, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 56 (4 ms) -- loss: 0.5872, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 57 (4 ms) -- loss: 0.4304, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 58 (4 ms) -- loss: 0.5512, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 59 (4 ms) -- loss: 0.5508, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 60 (4 ms) -- loss: 0.5174, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 61 (4 ms) -- loss: 0.4434, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 62 (4 ms) -- loss: 0.4910, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 63 (4 ms) -- loss: 0.4722, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 64 (4 ms) -- loss: 0.3710, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 65 (10 ms) -- loss: 0.4370, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 66 (5 ms) -- loss: 0.4384, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 67 (4 ms) -- loss: 0.5186, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 68 (4 ms) -- loss: 0.4479, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 69 (4 ms) -- loss: 0.4352, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 70 (5 ms) -- loss: 0.4451, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 71 (16 ms) -- loss: 0.4956, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 72 (18 ms) -- loss: 0.4941, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 73 (15 ms) -- loss: 0.3835, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 74 (38 ms) -- loss: 0.3687, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 75 (40 ms) -- loss: 0.3349, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 76 (46 ms) -- loss: 0.3630, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 77 (52 ms) -- loss: 0.4875, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 78 (33 ms) -- loss: 0.3445, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 79 (9 ms) -- loss: 0.5232, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 80 (10 ms) -- loss: 0.4692, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 81 (49 ms) -- loss: 0.4350, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 82 (98 ms) -- loss: 0.4030, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 83 (15 ms) -- loss: 0.2917, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 84 (11 ms) -- loss: 0.3671, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 85 (13 ms) -- loss: 0.4604, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 86 (13 ms) -- loss: 0.2994, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 87 (9 ms) -- loss: 0.3254, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 88 (22 ms) -- loss: 0.5054, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 89 (15 ms) -- loss: 0.4298, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 90 (23 ms) -- loss: 0.3668, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 91 (45 ms) -- loss: 0.3237, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 92 (14 ms) -- loss: 0.3803, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 93 (14 ms) -- loss: 0.3696, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 94 (13 ms) -- loss: 0.4683, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 95 (13 ms) -- loss: 0.3879, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 96 (11 ms) -- loss: 0.3649, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 97 (10 ms) -- loss: 0.3856, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 98 (12 ms) -- loss: 0.3575, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 99 (11 ms) -- loss: 0.3652, learning_rate: 0.5000\n",
      "INFO:tfutils:Step 100 (14 ms) -- loss: 0.4010, learning_rate: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist/b2/Momentum\n",
      "global_step\n",
      "mnist/W1/Momentum\n",
      "Variable_5\n",
      "mnist/b3/Momentum\n",
      "mnist/W3/Momentum\n",
      "mnist/b1\n",
      "mnist/b2\n",
      "mnist/b3\n",
      "Variable_3\n",
      "Variable_2\n",
      "Variable_1\n",
      "mnist/W2/Momentum\n",
      "Variable\n",
      "Variable_4\n",
      "mnist/b1/Momentum\n",
      "mnist/W3\n",
      "mnist/W2\n",
      "mnist/W1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tfutils:Saving model with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint ... \n",
      "INFO:tfutils:... done saving with path prefix /home/dan/.tfutils/localhost:24444/mnist/simple/exp1/checkpoint-100\n",
      "INFO:tfutils:Putting filters into <gridfs.GridFS object at 0x7fb3e9d95cd0> database\n",
      "INFO:tfutils:... done putting filters into database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[ObjectId('59dfd821d4fdab1c21d8be0a'), ObjectId('59dfd824d4fdab1c21d8be10')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import division\n",
    "from tfutils import base, data, optimizer, utils\n",
    "\n",
    "# delete exp1\n",
    "connection['mnist']['simple.files'].delete_many({'exp_id' : 'exp1'})\n",
    "\n",
    "def mnist_model(inputs, train=True, **kwargs):\n",
    "    # trainable variables randomly initialized\n",
    "    with tf.variable_scope(\"mnist\"):\n",
    "        W1 = tf.get_variable('W1', [784,128], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b1 = tf.get_variable('b1', [128], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        W2 = tf.get_variable('W2', [128,32], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b2 = tf.get_variable('b2', [32], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        W3 = tf.get_variable('W3', [32,10], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b3 = tf.get_variable('b3', [10], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        \n",
    "        # hidden layers\n",
    "        h1 = tf.nn.sigmoid(tf.matmul(inputs['images'], W1) + b1, name='hidden1')\n",
    "        h2 = tf.nn.sigmoid(tf.matmul(h1, W2) + b2, name='hidden2')\n",
    "        # output\n",
    "        output = tf.matmul(h2, W3) + b3\n",
    "\n",
    "    return output, {}\n",
    "\n",
    "params = {}\n",
    "\n",
    "params['load_params'] = {\n",
    "    'do_restore': False}\n",
    "\n",
    "params['save_params'] = {\n",
    "    'host': 'localhost',\n",
    "    'port': 24444,\n",
    "    'dbname': 'mnist',\n",
    "    'collname': 'simple',\n",
    "    'exp_id': 'exp1',\n",
    "    'save_valid_freq': 200,\n",
    "    'save_filters_freq': 100,\n",
    "    'cache_filters_freq': 100}\n",
    "\n",
    "params['train_params'] = {\n",
    "    'data_params': {'func': data.MNIST,\n",
    "                    'batch_size': 256,\n",
    "                    'group': 'train',\n",
    "                    'n_threads': 1},\n",
    "    'queue_params': {'queue_type': 'random',\n",
    "                     'batch_size': 256},\n",
    "    'num_steps': 100}\n",
    "\n",
    "params['model_params'] = {\n",
    "    'func': mnist_model} \n",
    "\n",
    "params['learning_rate_params'] = {\n",
    "    'learning_rate': 0.5,\n",
    "    'decay_steps': 500,\n",
    "    'decay_rate': 0.95,\n",
    "    'staircase': True}\n",
    "\n",
    "params['optimizer_params'] = {\n",
    "    'func': optimizer.ClipOptimizer,\n",
    "    'optimizer_class': tf.train.MomentumOptimizer,\n",
    "    'momentum': 0.9,\n",
    "    'clip': True,\n",
    "}\n",
    "\n",
    "params['loss_params'] = {\n",
    "    'targets': ['labels'],\n",
    "    'loss_per_case_func': tf.nn.sparse_softmax_cross_entropy_with_logits,\n",
    "    'agg_func': tf.reduce_mean\n",
    "}\n",
    "\n",
    "params['skip_check'] = True\n",
    "\n",
    "base.train_from_params(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Now let's load the trained model from the database and test it on the validation set using TFUtils. There are 10,000 examples in the MNIST test set.\n",
    "### Fill in the blanks marked with EDIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EDIT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cfae110a940d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m params['load_params'] = {\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;34m'host'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mEDIT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;34m'port'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mEDIT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;34m'dbname'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mEDIT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EDIT' is not defined"
     ]
    }
   ],
   "source": [
    "def top1_func(inputs, outputs): \n",
    "    \"\"\"\n",
    "    Computes the top1 accuracy with tf.nn.in_top_k\n",
    "    predictions = outputs\n",
    "    targets = inputs['labels']\n",
    "    \"\"\"\n",
    "    res = {'top1': EDIT}\n",
    "    return res\n",
    "\n",
    "def online_agg(agg_res, res, step):\n",
    "    \"\"\"\n",
    "    Appends the value for each key\n",
    "    \"\"\"\n",
    "    if agg_res is None:\n",
    "        agg_res = {k: [] for k in res}\n",
    "    for k, v in res.items():\n",
    "        agg_res[k].append(v)\n",
    "    return agg_res\n",
    "\n",
    "def agg_mean(x):\n",
    "    \"\"\"\n",
    "    Takes the mean of the aggregated results x\n",
    "    \"\"\"\n",
    "    return {k: np.mean(v) for k, v in x.items()}\n",
    "\n",
    "params = {}\n",
    "\n",
    "params['load_params'] = {\n",
    "    'host': EDIT,\n",
    "    'port': EDIT,\n",
    "    'dbname': EDIT,\n",
    "    'collname': EDIT,\n",
    "    'exp_id': EDIT,\n",
    "    'do_restore': EDIT}\n",
    "\n",
    "params['validation_params'] = {'valid0': {\n",
    "    'data_params': {EDIT},\n",
    "    'queue_params': {EDIT},\n",
    "    'targets': {EDIT},\n",
    "    'num_steps': EDIT,\n",
    "    'agg_func': EDIT,\n",
    "    'online_agg_func': EDIT,}}\n",
    "\n",
    "params['model_params'] = {\n",
    "    'func': EDIT}\n",
    "\n",
    "params['skip_check'] = True\n",
    "\n",
    "base.test_from_params(**params)\n",
    "\n",
    "# Extract record from database\n",
    "q_val = {'exp_id' : EDIT, 'validation_results' : {'$exists' : True}, 'validates': {'$exists': True}}\n",
    "val_steps = connection[EDIT]['EDIT.files'].find(EDIT)\n",
    "top1 = [val_steps[i][EDIT][EDIT][EDIT] \n",
    "        for i in range(val_steps.count())]\n",
    "print(top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Execute the script below to load the meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.in_top_k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load from tfrecords\n",
    "import cPickle\n",
    "import numpy as np\n",
    "data_path = '/datasets/neural_data/neural_data.pkl'\n",
    "with open(data_path) as f:\n",
    "    data = cPickle.load(f)\n",
    "meta = data['meta']\n",
    "IT_features = data['IT']\n",
    "meta.dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Select all files with 'Animals' or 'Cars' with a rotation in the xy-plane of more than 45 degrees and print how many there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "len((meta[((meta['category'] == 'Cars') | \n",
    "          (meta['category'] == 'Animals')) &\n",
    "          (meta['rxy'] > 45)]['obj']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.) Select all objects with 'GORILLA' that either have a variation level of 'V0' or a size 's' bigger 1 or both, and print the object names, their sizes 's' and variation levels as tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "subset = meta[(meta['obj'] == 'GORILLA') & \n",
    "             ((meta['var'] == 'V0') |\n",
    "             (meta['s'] > 1))]\n",
    "\n",
    "list(subset[['obj','s','var']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.) Perform a 8-way classification on the categories, using 20 splits, a 'svm.LinearSVC' classifier a 'C' of 5e-3 on variation level 'V0' for train and test.\n",
    "### Fill in the blanks marked with EDIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dldata.metrics.utils import compute_metric_base\n",
    "# Definition of classification experiment\n",
    "category_eval_spec = {\n",
    "    'npc_train': None,\n",
    "    'npc_test': 2,\n",
    "    'num_splits': EDIT,\n",
    "    'npc_validate': 0,\n",
    "    'metric_screen': EDIT,\n",
    "    'metric_labels': None,\n",
    "    'metric_kwargs': {'model_type': EDIT,\n",
    "                      'model_kwargs': {EDIT}\n",
    "                     },\n",
    "    'labelfunc': EDIT,\n",
    "    'train_q': {EDIT},\n",
    "    'test_q': {EDIT},\n",
    "    'split_by': 'obj'\n",
    "}\n",
    "# Execute classification experiment\n",
    "res = compute_metric_base(IT_features, meta, category_eval_spec)\n",
    "\n",
    "# Print results\n",
    "print('Overall accuracy of IT features on 8-way classification task: %.2f%%' % \\\n",
    "      ((np.array(res['result_summary']['accbal']).mean(0) - 0.5) * 2.0 * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.) Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cms = res['result_summary']['cms']).mean(2)\n",
    "axis_labels = res['result_summary']['labelset']\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
