{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-2, 2, 101)[np.random.RandomState(0).permutation(101)]\n",
    "y = x ** 3 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Insert x and y into the database \"tasks\", collection \"polyfunction\" on host \"localhost\", port \"24444\", read it out again in sorted order print \"x\" and plot \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "port = 24444\n",
    "host = 'localhost'\n",
    "connection = pm.MongoClient(port = port, host = host)\n",
    "\n",
    "entries = []\n",
    "for i in range(101):\n",
    "    entries.append({'x': x[i], 'y': y[i]})\n",
    "connection['tasks']['polyfunction'].insert_many(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = connection['tasks']['polyfunction'].find({'x': {'$exists' : True}}, projection=['x', 'y']).sort([('x',pm.ASCENDING)])\n",
    "x = [entry['x'] for entry in entries]\n",
    "print(x)\n",
    "entries = connection['tasks']['polyfunction'].find({'x': {'$exists' : True}}, projection=['x', 'y']).sort([('x',pm.ASCENDING)])\n",
    "y = [entry['y'] for entry in entries]\n",
    "plt.plot(x,y)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Run the script below which trains a MLP for the 10-way MNIST classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import division\n",
    "from tfutils import base, data, optimizer, utils\n",
    "\n",
    "# delete exp1\n",
    "connection['mnist']['simple.files'].delete_many({'exp_id' : 'exp1'})\n",
    "\n",
    "def mnist_model(inputs, train=True, **kwargs):\n",
    "    # trainable variables randomly initialized\n",
    "    with tf.variable_scope(\"mnist\"):\n",
    "        W1 = tf.get_variable('W1', [784,128], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b1 = tf.get_variable('b1', [128], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        W2 = tf.get_variable('W2', [128,32], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b2 = tf.get_variable('b2', [32], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        W3 = tf.get_variable('W3', [32,10], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        b3 = tf.get_variable('b3', [10], tf.float32, tf.random_normal_initializer(stddev=0.1))\n",
    "        \n",
    "        # hidden layers\n",
    "        h1 = tf.nn.sigmoid(tf.matmul(inputs['images'], W1) + b1, name='hidden1')\n",
    "        h2 = tf.nn.sigmoid(tf.matmul(h1, W2) + b2, name='hidden2')\n",
    "        # output\n",
    "        output = tf.matmul(h2, W3) + b3\n",
    "\n",
    "    return output, {}\n",
    "\n",
    "params = {}\n",
    "\n",
    "params['load_params'] = {\n",
    "    'do_restore': False}\n",
    "\n",
    "params['save_params'] = {\n",
    "    'host': 'localhost',\n",
    "    'port': 24444,\n",
    "    'dbname': 'mnist',\n",
    "    'collname': 'simple',\n",
    "    'exp_id': 'exp1',\n",
    "    'save_valid_freq': 200,\n",
    "    'save_filters_freq': 100,\n",
    "    'cache_filters_freq': 100}\n",
    "\n",
    "params['train_params'] = {\n",
    "    'data_params': {'func': data.MNIST,\n",
    "                    'batch_size': 256,\n",
    "                    'group': 'train',\n",
    "                    'n_threads': 1},\n",
    "    'queue_params': {'queue_type': 'random',\n",
    "                     'batch_size': 256},\n",
    "    'num_steps': 100}\n",
    "\n",
    "params['model_params'] = {\n",
    "    'func': mnist_model} \n",
    "\n",
    "params['learning_rate_params'] = {\n",
    "    'learning_rate': 0.5,\n",
    "    'decay_steps': 500,\n",
    "    'decay_rate': 0.95,\n",
    "    'staircase': True}\n",
    "\n",
    "params['optimizer_params'] = {\n",
    "    'func': optimizer.ClipOptimizer,\n",
    "    'optimizer_class': tf.train.MomentumOptimizer,\n",
    "    'momentum': 0.9,\n",
    "    'clip': True,\n",
    "}\n",
    "\n",
    "params['loss_params'] = {\n",
    "    'targets': ['labels'],\n",
    "    'loss_per_case_func': tf.nn.sparse_softmax_cross_entropy_with_logits,\n",
    "    'agg_func': tf.reduce_mean\n",
    "}\n",
    "\n",
    "params['skip_check'] = True\n",
    "\n",
    "base.train_from_params(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Now let's load the trained model from the database and test it on the validation set using TFUtils. There are 10,000 examples in the MNIST test set.\n",
    "### Fill in the blanks marked with EDIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top1_func(inputs, outputs): \n",
    "    \"\"\"\n",
    "    Computes the top1 accuracy with tf.nn.in_top_k\n",
    "    predictions = outputs\n",
    "    targets = inputs['labels']\n",
    "    \"\"\"\n",
    "    res = {'top1': EDIT}\n",
    "    return res\n",
    "\n",
    "def online_agg(agg_res, res, step):\n",
    "    \"\"\"\n",
    "    Appends the value for each key\n",
    "    \"\"\"\n",
    "    if agg_res is None:\n",
    "        agg_res = {k: [] for k in res}\n",
    "    for k, v in res.items():\n",
    "        agg_res[k].append(v)\n",
    "    return agg_res\n",
    "\n",
    "def agg_mean(x):\n",
    "    \"\"\"\n",
    "    Takes the mean of the aggregated results x\n",
    "    \"\"\"\n",
    "    return {k: np.mean(v) for k, v in x.items()}\n",
    "\n",
    "params = {}\n",
    "\n",
    "params['load_params'] = {\n",
    "    'host': EDIT,\n",
    "    'port': EDIT,\n",
    "    'dbname': EDIT,\n",
    "    'collname': EDIT,\n",
    "    'exp_id': EDIT,\n",
    "    'do_restore': EDIT}\n",
    "\n",
    "params['validation_params'] = {'valid0': {\n",
    "    'data_params': {EDIT},\n",
    "    'queue_params': {EDIT},\n",
    "    'targets': {EDIT},\n",
    "    'num_steps': EDIT,\n",
    "    'agg_func': EDIT,\n",
    "    'online_agg_func': EDIT,}}\n",
    "\n",
    "params['model_params'] = {\n",
    "    'func': EDIT}\n",
    "\n",
    "params['skip_check'] = True\n",
    "\n",
    "base.test_from_params(**params)\n",
    "\n",
    "# Extract record from database\n",
    "q_val = {'exp_id' : EDIT, 'validation_results' : {'$exists' : True}, 'validates': {'$exists': True}}\n",
    "val_steps = connection[EDIT]['EDIT.files'].find(EDIT)\n",
    "top1 = [val_steps[i][EDIT][EDIT][EDIT] \n",
    "        for i in range(val_steps.count())]\n",
    "print(top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Execute the script below to load the meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from tfrecords\n",
    "import cPickle\n",
    "import numpy as np\n",
    "data_path = '/datasets/neural_data/neural_data.pkl'\n",
    "with open(data_path) as f:\n",
    "    data = cPickle.load(f)\n",
    "meta = data['meta']\n",
    "IT_features = data['IT']\n",
    "meta.dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Select all files with 'Animals' or 'Cars' with a rotation in the xy-plane of more than 45 degrees and print how many there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.) Select all objects with 'GORILLA' that either have a variation level of 'V0' or a size 's' bigger 1 or both, and print the object names, their sizes 's' and variation levels as tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.) Perform a 8-way classification on the categories, using 20 splits, a 'svm.LinearSVC' classifier a 'C' of 5e-3 on variation level 'V0' for train and test.\n",
    "### Fill in the blanks marked with EDIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dldata.metrics.utils import compute_metric_base\n",
    "# Definition of classification experiment\n",
    "category_eval_spec = {\n",
    "    'npc_train': None,\n",
    "    'npc_test': 2,\n",
    "    'num_splits': EDIT,\n",
    "    'npc_validate': 0,\n",
    "    'metric_screen': EDIT,\n",
    "    'metric_labels': None,\n",
    "    'metric_kwargs': {'model_type': EDIT,\n",
    "                      'model_kwargs': {EDIT}\n",
    "                     },\n",
    "    'labelfunc': EDIT,\n",
    "    'train_q': {EDIT},\n",
    "    'test_q': {EDIT},\n",
    "    'split_by': 'obj'\n",
    "}\n",
    "# Execute classification experiment\n",
    "res = compute_metric_base(IT_features, meta, category_eval_spec)\n",
    "\n",
    "# Print results\n",
    "print('Overall accuracy of IT features on 8-way classification task: %.2f%%' % \\\n",
    "      ((np.array(res['result_summary']['accbal']).mean(0) - 0.5) * 2.0 * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.) Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cms = res['result_summary']['cms']).mean(2)\n",
    "axis_labels = res['result_summary']['labelset']\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
} 
